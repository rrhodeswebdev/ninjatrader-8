"""
Simplified Model Architecture

Conv1D + GRU hybrid optimized for financial time series prediction.
95% fewer parameters than original LSTM architecture to reduce overfitting.
"""

import torch
import torch.nn as nn
from typing import Tuple
import logging

logger = logging.getLogger(__name__)


class SimplifiedTradingModel(nn.Module):
    """
    Simplified architecture optimized for time series prediction

    Architecture:
    - 1D Convolution layers for local pattern extraction
    - GRU for temporal dependencies (lighter than LSTM)
    - Batch normalization for training stability
    - Dropout for regularization

    Complexity:
    - Old model: 166 features × 128 hidden × 20 sequence ≈ 425k parameters
    - New model: 28 features × 32 hidden × 20 sequence ≈ 18k parameters
    - Reduction: 95% fewer parameters
    """

    def __init__(self,
                 input_size: int = 28,
                 sequence_length: int = 20,
                 conv1_channels: int = 32,
                 conv2_channels: int = 16,
                 gru_hidden_size: int = 32,
                 dropout_rate: float = 0.3):
        """
        Args:
            input_size: Number of input features (28 essential features)
            sequence_length: Length of input sequences
            conv1_channels: First conv layer output channels
            conv2_channels: Second conv layer output channels
            gru_hidden_size: GRU hidden state size
            dropout_rate: Dropout probability for regularization
        """
        super(SimplifiedTradingModel, self).__init__()

        self.input_size = input_size
        self.sequence_length = sequence_length
        self.gru_hidden_size = gru_hidden_size

        # 1D Convolution for local pattern extraction
        # Replaces need for complex attention mechanisms
        self.conv1 = nn.Conv1d(
            in_channels=input_size,
            out_channels=conv1_channels,
            kernel_size=3,
            padding=1
        )

        self.conv2 = nn.Conv1d(
            in_channels=conv1_channels,
            out_channels=conv2_channels,
            kernel_size=3,
            padding=1
        )

        # Batch normalization for training stability
        self.bn1 = nn.BatchNorm1d(conv1_channels)
        self.bn2 = nn.BatchNorm1d(conv2_channels)

        # GRU for temporal dependencies (lighter than LSTM)
        # Single layer to reduce overfitting
        self.gru = nn.GRU(
            input_size=conv2_channels,
            hidden_size=gru_hidden_size,
            num_layers=1,
            batch_first=True,
            dropout=0.0  # No dropout between layers (only 1 layer)
        )

        # Dropout for regularization
        self.dropout = nn.Dropout(dropout_rate)

        # Output layers
        self.fc1 = nn.Linear(gru_hidden_size, 16)
        self.fc2 = nn.Linear(16, 1)

        # Activation functions
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

        # Initialize weights
        self._initialize_weights()

        logger.info(f"Initialized SimplifiedTradingModel with {self._count_parameters()} parameters")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass

        Args:
            x: Input tensor of shape (batch, sequence_length, features)

        Returns:
            Output tensor of shape (batch, 1) - probability of upward movement
        """
        batch_size = x.size(0)

        # Transpose for Conv1d: (batch, features, sequence_length)
        x = x.transpose(1, 2)

        # Convolutional feature extraction
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)

        # Transpose back for GRU: (batch, sequence_length, features)
        x = x.transpose(1, 2)

        # Temporal modeling with GRU
        gru_out, _ = self.gru(x)

        # Use last timestep output
        x = gru_out[:, -1, :]

        # Dropout regularization
        x = self.dropout(x)

        # Output layers
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.sigmoid(x)

        return x

    def _initialize_weights(self):
        """Initialize weights using Xavier/He initialization"""
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.GRU):
                for name, param in m.named_parameters():
                    if 'weight_ih' in name:
                        nn.init.xavier_normal_(param)
                    elif 'weight_hh' in name:
                        nn.init.orthogonal_(param)
                    elif 'bias' in name:
                        nn.init.constant_(param, 0)

    def _count_parameters(self) -> int:
        """Count trainable parameters"""
        return sum(p.numel() for p in self.parameters() if p.requires_grad)

    def get_model_info(self) -> dict:
        """
        Get model architecture information

        Returns:
            Dictionary with model details
        """
        return {
            'architecture': 'Conv1D + GRU',
            'input_size': self.input_size,
            'sequence_length': self.sequence_length,
            'gru_hidden_size': self.gru_hidden_size,
            'total_parameters': self._count_parameters(),
            'trainable_parameters': sum(p.numel() for p in self.parameters() if p.requires_grad)
        }


class EnsembleModel(nn.Module):
    """
    Ensemble of multiple SimplifiedTradingModel instances

    Reduces variance and improves robustness through model averaging
    """

    def __init__(self, num_models: int = 3, **model_kwargs):
        """
        Args:
            num_models: Number of models in ensemble
            **model_kwargs: Arguments passed to SimplifiedTradingModel
        """
        super(EnsembleModel, self).__init__()

        self.num_models = num_models
        self.models = nn.ModuleList([
            SimplifiedTradingModel(**model_kwargs)
            for _ in range(num_models)
        ])

        logger.info(f"Initialized ensemble with {num_models} models")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Forward pass through ensemble

        Args:
            x: Input tensor

        Returns:
            Average prediction across all models
        """
        predictions = []

        for model in self.models:
            pred = model(x)
            predictions.append(pred)

        # Average predictions
        ensemble_pred = torch.stack(predictions).mean(dim=0)

        return ensemble_pred

    def get_prediction_variance(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Get both mean prediction and variance across ensemble

        Useful for uncertainty quantification

        Args:
            x: Input tensor

        Returns:
            (mean_prediction, variance)
        """
        predictions = []

        for model in self.models:
            pred = model(x)
            predictions.append(pred)

        predictions_stack = torch.stack(predictions)
        mean_pred = predictions_stack.mean(dim=0)
        variance = predictions_stack.var(dim=0)

        return mean_pred, variance


def create_model(input_size: int = 28,
                sequence_length: int = 20,
                use_ensemble: bool = False,
                num_ensemble_models: int = 3) -> nn.Module:
    """
    Factory function to create model

    Args:
        input_size: Number of input features
        sequence_length: Sequence length
        use_ensemble: Whether to create ensemble model
        num_ensemble_models: Number of models in ensemble

    Returns:
        Model instance
    """
    if use_ensemble:
        model = EnsembleModel(
            num_models=num_ensemble_models,
            input_size=input_size,
            sequence_length=sequence_length
        )
    else:
        model = SimplifiedTradingModel(
            input_size=input_size,
            sequence_length=sequence_length
        )

    logger.info(f"Created model: {model.__class__.__name__}")

    return model


def load_model(checkpoint_path: str,
              input_size: int = 28,
              sequence_length: int = 20,
              device: str = 'cpu') -> nn.Module:
    """
    Load model from checkpoint

    Args:
        checkpoint_path: Path to model checkpoint
        input_size: Number of input features
        sequence_length: Sequence length
        device: Device to load model on

    Returns:
        Loaded model
    """
    model = SimplifiedTradingModel(
        input_size=input_size,
        sequence_length=sequence_length
    )

    checkpoint = torch.load(checkpoint_path, map_location=device)

    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)

    model.to(device)
    model.eval()

    logger.info(f"Loaded model from {checkpoint_path}")

    return model


def save_model(model: nn.Module,
              filepath: str,
              optimizer = None,
              epoch: int = None,
              metrics: dict = None):
    """
    Save model checkpoint

    Args:
        model: Model to save
        filepath: Path to save checkpoint
        optimizer: Optimizer state (optional)
        epoch: Current epoch (optional)
        metrics: Training metrics (optional)
    """
    checkpoint = {
        'model_state_dict': model.state_dict(),
        'model_info': model.get_model_info() if hasattr(model, 'get_model_info') else {}
    }

    if optimizer is not None:
        checkpoint['optimizer_state_dict'] = optimizer.state_dict()

    if epoch is not None:
        checkpoint['epoch'] = epoch

    if metrics is not None:
        checkpoint['metrics'] = metrics

    torch.save(checkpoint, filepath)
    logger.info(f"Saved model to {filepath}")
